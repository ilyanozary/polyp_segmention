{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9594dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45359ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Creating a directory \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\"\"\" Function to load and resize images \"\"\"\n",
    "def load_and_resize_images(image_paths, size=(224, 224), is_mask=False):\n",
    "    images = []\n",
    "    for path in tqdm(image_paths, desc=\"Resizing images\" if not is_mask else \"Resizing masks\"):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if is_mask else cv2.IMREAD_COLOR)  # Load mask in grayscale, image in color\n",
    "        img = cv2.resize(img, size)  # Resize image/mask to 512x512\n",
    "        if not is_mask:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for images\n",
    "        else:\n",
    "            img = np.expand_dims(img, axis=-1)  # Add channel dimension for masks\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype='float32')\n",
    "\n",
    "\"\"\" Function to load dataset and split into train, validation, and test sets \"\"\"\n",
    "def load_data(path):\n",
    "    \"\"\" Loading the images and masks \"\"\"\n",
    "    X = sorted(glob(os.path.join(path, \"images\", \"*.jpg\")))\n",
    "    Y = sorted(glob(os.path.join(path, \"masks\", \"*.jpg\")))\n",
    "\n",
    "    \"\"\" Splitting the data into 80% training, 10% validation, 10% testing \"\"\"\n",
    "    train_x, temp_x, train_y, temp_y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, test_size=0.5, random_state=42)\n",
    "\n",
    "    \"\"\" Resize images and masks \"\"\"\n",
    "    train_x = load_and_resize_images(train_x)\n",
    "    val_x = load_and_resize_images(val_x)\n",
    "    test_x = load_and_resize_images(test_x)\n",
    "\n",
    "    train_y = load_and_resize_images(train_y, is_mask=True)\n",
    "    val_y = load_and_resize_images(val_y, is_mask=True)\n",
    "    test_y = load_and_resize_images(test_y, is_mask=True)\n",
    "\n",
    "    \"\"\" Normalize images and masks to the range [0, 1] \"\"\"\n",
    "    train_x = train_x / 255.0\n",
    "    val_x = val_x / 255.0\n",
    "    test_x = test_x / 255.0\n",
    "\n",
    "    train_y = train_y / 255.0\n",
    "    val_y = val_y / 255.0\n",
    "    test_y = test_y / 255.0\n",
    "\n",
    "    return (train_x, train_y), (val_x, val_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc473c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \"\"\" Load the dataset \"\"\"\n",
    "    data_path = \"Kvasir-SEG/Kvasir-SEG\"\n",
    "    (train_x, train_y), (val_x, val_y), (test_x, test_y) = load_data(data_path)\n",
    "\n",
    "    print(f\"Train:\t {len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Validation:\t {len(val_x)} - {len(val_y)}\")\n",
    "    print(f\"Test:\t {len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "    \"\"\" Debugging: Check shapes and data types \"\"\"\n",
    "    print(\"Train X shape:\", train_x.shape)\n",
    "    print(\"Train Y shape:\", train_y.shape)\n",
    "    print(\"Validation X shape:\", val_x.shape)\n",
    "    print(\"Validation Y shape:\", val_y.shape)\n",
    "    print(\"Test X shape:\", test_x.shape)\n",
    "    print(\"Test Y shape:\", test_y.shape)\n",
    "\n",
    "    print(\"Train X dtype:\", train_x.dtype)\n",
    "    print(\"Train Y dtype:\", train_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d89079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def display_image_mask_pairs(images, masks, title, num_images=10):\n",
    "    \"\"\" Display a set of images with their corresponding masks (from preloaded arrays) \"\"\"\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    for i in range(min(num_images, len(images))):\n",
    "        img = images[i]  # Image array (already loaded and normalized)\n",
    "        mask = masks[i]  # Mask array (already loaded and normalized)\n",
    "        \n",
    "        # Plot original image\n",
    "        plt.subplot(num_images, 2, 2 * i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{title} - Image {i+1}\")\n",
    "        \n",
    "        # Plot mask\n",
    "        plt.subplot(num_images, 2, 2 * i + 2)\n",
    "        plt.imshow(mask.squeeze(), cmap=\"gray\")  # Remove channel dimension for display\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{title} - Mask {i+1}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display using preloaded arrays (no file paths)\n",
    "display_image_mask_pairs(train_x, train_y, \"Training Set\", 2)\n",
    "display_image_mask_pairs(val_x, val_y, \"Validation Set\", 2)\n",
    "display_image_mask_pairs(test_x, test_y, \"Testing Set\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ddf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, BatchNormalization, Activation, MaxPool2D,\n",
    "    Conv2DTranspose, Concatenate, Input, AveragePooling2D,\n",
    "    GlobalAveragePooling2D, UpSampling2D, Reshape, Dense\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def ASPP(inputs):\n",
    "    \"\"\" Atrous Spatial Pyramid Pooling (ASPP) \"\"\"\n",
    "    shape = K.int_shape(inputs)  # Use Keras static shape instead of tf.shape\n",
    "    h, w = shape[1], shape[2]\n",
    "\n",
    "    y1 = AveragePooling2D(pool_size=(h, w))(inputs)\n",
    "    y1 = Conv2D(256, 1, padding=\"same\", use_bias=False)(y1)\n",
    "    y1 = BatchNormalization()(y1)\n",
    "    y1 = Activation(\"relu\")(y1)\n",
    "    y1 = UpSampling2D((h, w), interpolation=\"bilinear\")(y1)\n",
    "\n",
    "    y2 = Conv2D(256, 1, padding=\"same\", use_bias=False)(inputs)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = Activation(\"relu\")(y2)\n",
    "\n",
    "    y3 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=6)(inputs)\n",
    "    y3 = BatchNormalization()(y3)\n",
    "    y3 = Activation(\"relu\")(y3)\n",
    "\n",
    "    y4 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=12)(inputs)\n",
    "    y4 = BatchNormalization()(y4)\n",
    "    y4 = Activation(\"relu\")(y4)\n",
    "\n",
    "    y5 = Conv2D(256, 3, padding=\"same\", use_bias=False, dilation_rate=18)(inputs)\n",
    "    y5 = BatchNormalization()(y5)\n",
    "    y5 = Activation(\"relu\")(y5)\n",
    "\n",
    "    y = Concatenate()([y1, y2, y3, y4, y5])\n",
    "    y = Conv2D(256, 1, padding=\"same\", use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(\"relu\")(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def deeplabv3_plus(shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(shape=shape)\n",
    "\n",
    "    \"\"\" Encoder using MobileNetV2 \"\"\"\n",
    "    encoder = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
    "    \n",
    "    image_features = encoder.get_layer(\"block_13_expand_relu\").output  # High-level features\n",
    "    x_a = ASPP(image_features)\n",
    "    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
    "\n",
    "    x_b = encoder.get_layer(\"block_3_expand_relu\").output  # Low-level features\n",
    "    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
    "    x_b = BatchNormalization()(x_b)\n",
    "    x_b = Activation('relu')(x_b)\n",
    "\n",
    "    x = Concatenate()([x_a, x_b])\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
    "    x = Conv2D(1, 1)(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = deeplabv3_plus((224, 224, 3))\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Intersection over Union (IoU)**\n",
    "def iou(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return intersection / (union + K.epsilon())\n",
    "\n",
    "# **Dice Coefficient**\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "\n",
    "# **Precision**\n",
    "def precision(y_true, y_pred):\n",
    "    true_positive = K.sum(K.round(y_true * y_pred))\n",
    "    predicted_positive = K.sum(K.round(y_pred))\n",
    "    return true_positive / (predicted_positive + K.epsilon())\n",
    "\n",
    "# **Recall**\n",
    "def recall(y_true, y_pred):\n",
    "    true_positive = K.sum(K.round(y_true * y_pred))\n",
    "    possible_positive = K.sum(K.round(y_true))\n",
    "    return true_positive / (possible_positive + K.epsilon())\n",
    "\n",
    "\n",
    "# **Binary Accuracy**\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_predictions = K.sum(K.cast(K.equal(K.round(y_true), K.round(y_pred)), dtype=\"float32\"))\n",
    "    total_predictions = K.cast(K.prod(K.shape(y_true)), dtype=\"float32\")\n",
    "    return correct_predictions / (total_predictions + K.epsilon())\n",
    "\n",
    "\n",
    "# **Focal Loss**\n",
    "def focal_loss(alpha=0.8, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, 1e-7, 1.0 - 1e-7)  # Avoid log(0)\n",
    "        focal_weight = alpha * K.pow(1 - y_pred, gamma) * y_true + (1 - alpha) * K.pow(y_pred, gamma) * (1 - y_true)\n",
    "        return K.mean(focal_weight * K.binary_crossentropy(y_true, y_pred))\n",
    "    return loss\n",
    "\n",
    "# **Dice Loss**\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def mixed_loss(y_true, y_pred):\n",
    "    return focal_loss()(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "initial_learning_rate = 0.0005  \n",
    "decay_steps = 1000  \n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=mixed_loss,\n",
    "              metrics=[accuracy, precision, recall, dice_coefficient, iou])\n",
    "\n",
    "batch_size = 4  \n",
    "epochs = 10\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(val_x, val_y),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a24766",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x[:5])\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(test_x[i])\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.imshow(test_y[i].squeeze(), cmap='gray')\n",
    "    plt.title(\"True Mask\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.imshow(predictions[i].squeeze() > 0.5, cmap='gray')\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cfe3b",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models\\deeplabv3_plus&mobilenet_kvasir.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b007ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
